{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Sale Price of Bulldozers using Machine Learning\n",
    "\n",
    "In this notebook, we're going to go through an example of machine learning project with the goal of predicting the sale price of bulldozers.\n",
    "\n",
    "## 1. Problem Definition\n",
    "\n",
    "> How well can we predict the future sale price of a bulldozer, given its characterisitcs and previous examples of how much similar bulldozers have been sold for?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "The data is downloaded from the Kaggle Bluebook for Bulldozers competition: https://www.kaggle.com/c/bluebook-for-bulldozers/data\n",
    "\n",
    "There are 3 main datasets:\n",
    "\n",
    "* Train.csv is the training set, which contains data through the end of 2011.\n",
    "* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012. You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "* Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "\n",
    "For more on the evaluation of this project check:\n",
    "https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation\n",
    "\n",
    "**Note:** The goal for most regression evaluation metrics is to minimise the error. For example, our goal for this project will be to build a machine learning model which minimizes RMSLE.\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "Kaggle provides a data dictionary detailing all of the features of the dataset. You can view this data dictionary on Google Sheets:\n",
    "https://www.kaggle.com/c/bluebook-for-bulldozers/data?select=Data+Dictionary.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA Tools:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and validation sets\n",
    "# guessing dtypes for each col is memory demanding\n",
    "# Pandas tries to determine what dtype to set in each column.\n",
    "df = pd.read_csv(\"bluebook-for-bulldozers/TrainAndValid.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting between saledate & saleprice\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df.saledate[:1000],df.SalePrice[:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histogram for observing distribution\n",
    "df.SalePrice.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dates\n",
    "\n",
    "When we work with time series data, we want to enrich the time & date component as much as possible.\n",
    "\n",
    "We can do that by telling pandas which of our columns have dates in it using the `parse_dates` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data again but this time parse dates\n",
    "df = pd.read_csv(\"bluebook-for-bulldozers/TrainAndValid.csv\",\n",
    "                 low_memory=False,\n",
    "                 parse_dates=[\"saledate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df.saledate[:1000],df.SalePrice[:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort DataFrame by saledate\n",
    "\n",
    "When working with time-series data, it's a good idea to sort it by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by saledate\n",
    "df.sort_values(\"saledate\", inplace=True, ascending=True)\n",
    "df.saledate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the original dataframe\n",
    "\n",
    "We make a copy of the original dataframe so when we manipulate the copy, we still got our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df.copy()\n",
    "df_tmp.saledate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've parsed saledate and sort the dataframe as per sorted date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add datetime parameters for `saledate` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[:1].saledate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 5 new cols:\n",
    "df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\n",
    "df_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\n",
    "df_tmp[\"saleDay\"] = df_tmp.saledate.dt.day\n",
    "df_tmp[\"saleDayOfWeek\"] = df_tmp.saledate.dt.dayofweek \n",
    "# (0: Mon, 1: Tue, 2: Wed, 3:Thu, 4: Fri, 5: Sat, 6:Sun)\n",
    "df_tmp[\"saleDayOfYear\"] = df_tmp.saledate.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've enriched our dataframe with datetime features, we can remove `saledate`\n",
    "df_tmp.drop([\"saledate\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling\n",
    "\n",
    "We've done enough EDA (we could always do more) but let's start to do some model-driven EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate a model\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(df_tmp.drop(\"SalePrice\",axis=1),df_tmp[\"SalePrice\"])\n",
    "# Error since it cannot convert string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"UsageBand\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert strings to categories\n",
    "\n",
    "One way we can turn all of our data into numbers is by converting them into panda categories.\n",
    "\n",
    "We can check the different datatypes compatible with pandas here:\n",
    "https://pandas.pydata.org/pandas-docs/version/0.25.3/reference/general_utility_functions.html#data-types-related-functionality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_string_dtype(df_tmp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the columns which contain strings\n",
    "for name, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"UsageBand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all of the string values into category values\n",
    "for name, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[name] = content.astype(\"category\").cat.as_ordered()\n",
    "# while converting to categories it converts missing values(NaN) to -1 in codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"UsageBand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"UsageBand\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to Pandas categories we now have a way to access all of our data in the form of numbers. \n",
    "\n",
    "But we still have a bunch of missing data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data\n",
    "df_tmp.isnull().sum()/len(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export current tmp dataframe\n",
    "df_tmp.to_csv(\"bull.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data\n",
    "df_temp = pd.read_csv(\"bull.csv\", low_memory=False)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values\n",
    "\n",
    "#### Fill numerical missing values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values\n",
    "for name, content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric rows with the median\n",
    "for name, content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            # Add a column which tells us if the data was missing or not\n",
    "            df_temp[name+\"_is_missing\"] = pd.isnull(content)\n",
    "            # Fill missing numeric values with median\n",
    "            df_temp[name] = content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's any missing numeric values left\n",
    "for name, content in df_temp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how many examples were missing\n",
    "df_temp.auctioneerID_is_missing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns which aren't numeric\n",
    "for name, content in df_temp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.state.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_temp[\"state\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_temp[\"UsageBand\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_temp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categorical variables into numbers\n",
    "# Fill already took place when converting\n",
    "# Missing places filled by -1\n",
    "\n",
    "for name, content in df_temp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        # Add columns to indicate whether sample had missing values\n",
    "        df_temp[name+\"_is_missing\"] = pd.isnull(content)\n",
    "        # Turn categories into numbers and add +1\n",
    "        df_temp[name] = pd.Categorical(content).codes + 1\n",
    "        \n",
    "# pd.Categorical(content).codes assign value -1 in the missing place codes and we dont want that\n",
    "# so as to fill all numbers with positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.UsageBand.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_temp[\"UsageBand\"]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our data numeric as well as our dataframe has no missing values, we should be able to build a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# let's build a machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate a model\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "#model.fit(df_temp.drop(\"SalePrice\",axis=1),df_temp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "# model.score(df_temp.drop(\"SalePrice\",axis=1),df_temp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why doesn't the above metric hold water? (why isn't the metric reliable)\n",
    "\n",
    "**Generalization:** The ability for a machine learning model to perform well on data it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.saleYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting data into train & validation sets:\n",
    "\n",
    "df_val = df_temp[df_temp.saleYear==2012]\n",
    "df_train = df_temp[df_temp.saleYear!=2012]\n",
    "len(df_val), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X & y\n",
    "X_train, y_train = df_train.drop(\"SalePrice\",axis=1), df_train[\"SalePrice\"]\n",
    "X_valid, y_valid = df_val.drop(\"SalePrice\",axis=1), df_val[\"SalePrice\"]\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (the competition uses RMSLE)\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n",
    "\n",
    "def rmsle(y_true,y_preds):\n",
    "    \"\"\"\n",
    "    Calculates root mean squared log error between predictions & true labels.\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_true,y_preds))\n",
    "\n",
    "# Create function to evaluate model on few different levels\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
    "              \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n",
    "              \"Training RMSLE\": rmsle(y_train, train_preds),\n",
    "              \"Valid RMSLE\": rmsle(y_valid, val_preds),\n",
    "              \"Training R^2\": r2_score(y_train, train_preds),\n",
    "              \"Valid R^2\": r2_score(y_valid, val_preds)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Testing our model on a subset (to tune the hyperparamters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes far too long... for experimenting\n",
    "\n",
    "# %%time\n",
    "# model = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change max_samples value (Training on 10000 records)\n",
    "model = RandomForestRegressor(n_jobs=-1,\n",
    "                              random_state=42,\n",
    "                              max_samples=10000)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cutting down on the max number of samples each estimator can see improves training time\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Different RandomForestRegressor hyperparameters\n",
    "rf_grid = {\"n_estimators\": np.arange(10,100,10),\n",
    "           \"max_depth\": [None, 3, 5, 10],\n",
    "           \"min_samples_split\": np.arange(2,20,2),\n",
    "           \"min_samples_leaf\": np.arange(1,20,2),\n",
    "           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"],\n",
    "           \"max_samples\": [10000]}\n",
    "\n",
    "# Instantiate RandomizedSearchCV model\n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n",
    "                                                    random_state=42),\n",
    "                              param_distributions = rf_grid,\n",
    "                              n_iter = 2,\n",
    "                              cv = 5,\n",
    "                              verbose = True)\n",
    "\n",
    "# Fit the RandomizedSearchCV model\n",
    "rs_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best hyperparameters\n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the RandomizedSearch model\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model with the best hyperparameters\n",
    "\n",
    "**Note:** These were found after 100 iterations of `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Most ideal hyperparameters\n",
    "ideal_model = RandomForestRegressor(n_estimators=40,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_samples_split=14,\n",
    "                                    max_features=0.5,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_samples=None,\n",
    "                                    random_state=42)\n",
    "\n",
    "# Fit the ideal model\n",
    "ideal_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores for ideal model (trained on all data)\n",
    "show_scores(ideal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores on rs_model (only trained on 10000 examples)\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test data\n",
    "df_test = pd.read_csv(\"bluebook-for-bulldozers/Test.csv\",\n",
    "                      low_memory=False,\n",
    "                      parse_dates=[\"saledate\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data (getting the test dataset in the same format as our training & validation dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Performs transformations on df and returns transformed df.\n",
    "    \"\"\"\n",
    "    df[\"saleYear\"] = df.saledate.dt.year\n",
    "    df[\"saleMonth\"] = df.saledate.dt.month\n",
    "    df[\"saleDay\"] = df.saledate.dt.day\n",
    "    df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek \n",
    "    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "    \n",
    "    df.drop(\"saledate\", axis=1, inplace=True)\n",
    "    \n",
    "    # Fill the empty numeric rows with median\n",
    "    for name, content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "                df[name+\"_is_missing\"] = pd.isnull(content)\n",
    "                df[name] = content.fillna(content.median())\n",
    "        \n",
    "        # Filling categorical missing data and turning categories into numbers\n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            df[name+\"_is_missing\"] = pd.isnull(content)\n",
    "            df[name] = pd.Categorical(content).codes+1\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test data\n",
    "df_test = preprocess_data(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find how the columns differ using sets\n",
    "set(X_train.columns)-set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'auctioneerID' in the training set contains missing values but not in the test set\n",
    "df_test['auctioneerID_is_missing'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(df):\n",
    "#     \"\"\"\n",
    "#     Performs transformations on df and returns transformed df.\n",
    "#     \"\"\"\n",
    "   \n",
    "#     df[\"saleYear\"] = df.saledate.dt.year\n",
    "#     df[\"saleMonth\"] = df.saledate.dt.month\n",
    "#     df[\"saleDay\"] = df.saledate.dt.day\n",
    "#     df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek \n",
    "#     df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "    \n",
    "#     df.drop(\"saledate\", axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "#     for label, content in df.items():\n",
    "#         # Turning categories into numbers\n",
    "#         if not pd.api.types.is_numeric_dtype(content):\n",
    "#             df[label] = content.astype(\"category\").cat.as_ordered()\n",
    "            \n",
    "#         # Fill the numeric rows with median\n",
    "#         if pd.api.types.is_numeric_dtype(content):\n",
    "#             if pd.isnull(content).sum():\n",
    "#                 df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "#                 df[label] = content.fillna(content.median())\n",
    "        \n",
    "#         # Filling categorical missing data \n",
    "#         if not pd.api.types.is_numeric_dtype(content):\n",
    "#             df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "#             df[label] = pd.Categorical(content).codes+1\n",
    "            \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = preprocess_data(df_test)\n",
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally now our test dataframe has same features as training dataframe and we can make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've made some predictions but they're not in the same format Kaggle is asking for: https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions into the same format Kaggle is after\n",
    "df_preds = pd.DataFrame()\n",
    "df_preds[\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_preds[\"SalesPrice\"] = test_preds\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Prediction Data\n",
    "df_preds.to_csv(\"bulldozer_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature Importance seeks to figure out which different attributes of the data were most importance when it comes to predicting the target variable(**Sale Price**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find feature importance of our best model\n",
    "ideal_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.DataFrame({\"features\": X_train.columns,\n",
    "                    \"feature_importances\": ideal_model.feature_importances_})\n",
    "      .sort_values(\"feature_importances\", ascending=False)\n",
    "      .reset_index(drop=True))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting feature importance\n",
    "def plot_features(columns, importances, n=20):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                        \"feature_importances\": importances})\n",
    "          .sort_values(\"feature_importances\", ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    # Plot the dataframes\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:n])\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.set_xlabel(\"Feature Importance\")\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns, ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to finish:** Why might knowing the feature importances of a trained machine learning model be helpful?\n",
    "\n",
    "**Final Challenge:**  What other machine learning models could you try on this dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
